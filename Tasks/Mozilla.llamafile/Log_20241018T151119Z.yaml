Installer:
- InstallerUrl: https://github.com/Mozilla-Ocho/llamafile/releases/download/0.8.14/llamafile-0.8.14
Locale:
- Locale: en-US
  Key: ReleaseNotes
  Value: |-
    This release introduces our new CLI chatbot interface. It supports multi-line input using triple quotes. It will syntax highlight Python, C, C++, Java, and JavaScript code.
    This chatbot is now the default mode of operation. When you launch llamafile without any special arguments, the chatbot will be launched in the foreground, and the server will be launched in the background. You can use the --chat and --server flags to disambiguate this behavior if you only want one of them.
    - a384fd7 Create ollama inspired cli chatbot
    - 63205ee Add syntax highlighting to chatbot
    - 7b395be Introduce new --chat flag for chatbot
    - 28e98b6 Show prompt loading progress in chatbot
    - 4199dae Make chat+server hybrid the new default mode
    The whisperfile server now lets you upload mp3/ogg/flac.
    - 74dfd21 Rewrite audio file loader code
    - 7517a5f whisperfile server: convert files without ffmpeg (#568)
    Other improvements have been made.
    - d617c0b Added vision support to api_like_OAI (#524)
    - 726f6e8 Enable gpu support in llamafile-bench (#581)
    - c7c4d65 Speed up KV in llamafile-bench
    - 2c940da Make replace_all() have linear complexity
    - fa4c4e7 Use bf16 kv cache when it's faster
    - 20fe696 Upgrade to Cosmopolitan 3.9.4
    - c44664b Always favor fp16 arithmetic in tinyBLAS
    - 98eff09 Quantize TriLM models using Q2_K_S (#552)
- Key: ReleaseNotesUrl
  Value: https://github.com/Mozilla-Ocho/llamafile/releases/tag/0.8.14
Version: 0.8.14
ReleaseTime: 2024-10-14T01:56:21.0000000Z
