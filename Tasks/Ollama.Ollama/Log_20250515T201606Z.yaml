Version: 0.7.0
Installer:
- InstallerType: inno
  InstallerUrl: https://github.com/ollama/ollama/releases/download/v0.7.0/OllamaSetup.exe
- Architecture: x64
  InstallerType: portable
  InstallerUrl: https://github.com/ollama/ollama/releases/download/v0.7.0/ollama-windows-amd64-rocm.zip
Locale:
- Locale: en-US
  Key: ReleaseNotes
  Value: |-
    Ollama now supports multimodal models via Ollamaâ€™s new engine, starting with new vision multimodal models:
    - Meta Llama 4
    - Google Gemma 3
    - Qwen 2.5 VL
    - Mistral Small 3.1
    - and more vision models.
    What's Changed
    - Fixed issue where a blank terminal window would appear when runnings models on Windows
    - Fixed error that would occur when running llama4 on NVIDIA GPUs
    - Reduced log level of key not found message
    - Ollama will now correct remove quotes from image paths when sending images as input with ollama run
    - Improved performance of importing safetensors models via ollama create
    - Improved prompt processing speeds of Qwen3 MoE on macOS
    - Fixed issue where providing large JSON schemas in structured output requests would result in an error
    - Ollama's API will now return code 405 instead of 404 for methods that are not allowed
    - Fixed issue where ollama processes would continue to run after a model was unloaded
    New Contributors
    - @ashokgelal made their first contribution in https://github.com/ollama/ollama/pull/8668
    - @Aharon-Bensadoun made their first contribution in https://github.com/ollama/ollama/pull/9719
    - @HardCodeDev777 made their first contribution in https://github.com/ollama/ollama/pull/10664
    Full Changelog: https://github.com/ollama/ollama/compare/v0.6.8...v0.7.0
- Key: ReleaseNotesUrl
  Value: https://github.com/ollama/ollama/releases/tag/v0.7.0
ReleaseTime: 2025-05-13T00:10:33.0000000Z
