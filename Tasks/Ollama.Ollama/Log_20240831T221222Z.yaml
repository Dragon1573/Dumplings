Installer:
- InstallerType: inno
  InstallerUrl: https://github.com/ollama/ollama/releases/download/v0.3.9/OllamaSetup.exe
- Architecture: x64
  InstallerType: portable
  InstallerUrl: https://github.com/ollama/ollama/releases/download/v0.3.9/ollama-windows-amd64.zip
Locale:
- Locale: en-US
  Key: ReleaseNotes
  Value: |-
    What's Changed
    - Fixed error that would occur when running Ollama on Linux machines with the ARM architecture
    - Ollama will now show an improved error message when attempting to run unsupported models
    - Fixed issue where Ollama would not auto-detect the chat template for Llama 3.1 models
    - OLLAMA_HOST will now work with with URLs that contain paths
    New Contributors
    - @bryanhonof made their first contribution in https://github.com/ollama/ollama/pull/6074
    Full Changelog: https://github.com/ollama/ollama/compare/v0.3.8...v0.3.9
- Key: ReleaseNotesUrl
  Value: https://github.com/ollama/ollama/releases/tag/v0.3.9
Version: 0.3.9
ReleaseTime: 2024-08-31T19:26:05.0000000Z
