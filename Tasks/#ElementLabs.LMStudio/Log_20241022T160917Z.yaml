Installer: []
Locale:
- Locale: en-US
  Key: ReleaseNotes
  Value: |-
    0. 3.5 - Release Notes
    - Run LM Studio as a service (headless)
      - lms load, lms server start no longer requires launching the GUI
      - ability to run on machine startup
    - Server start / stop button will remember last setting
      - This is useful when LM Studio is running as a service
    - Improvement to Model Search
      - Hugging Face search now happens automatically without Cmd / Ctrl + Enter
    - Just-In-Time model loading for OpenAI endpoints
    - Button to toggle Mission Control full screen / modal modes
    - Update llama.cpp-based JSON response generation; now supports more complex JSON schemas
    - Tray menu options to minimize app to tray, copy server base URL
    - Checkbox to add lms to PATH during onboarding on Linux
    - [Mac][MLX Vision] Bump mlx-vlm version to 0.0.15, support Qwen2VL
    - [Mac][MLX Engine] Updated Transformers to 4.45.0
      - Fixes some issues with sideloading quantized MLX models (https://github.com/lmstudio-ai/mlx-engine/issues/10)
    - [UI] Move Chat Appearance control to top bar
    - [UI] Tweaks to size of per-message action buttons
    - Localization:
      - Improved German translation thanks to Goekdeniz-Guelmez
      - Indonesian translation thanks to dwirx
    Bug fixes
    - [Bug fix] fix RAG reinjecting document into context on follow up prompts
    - Fixed RAG not working (https://github.com/lmstudio-ai/mlx-engine/issues/4)
    - Fix outline flicker around Mission Control
Version: 0.3.5
